{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Machine Learning approach for Malware prediction in Windows systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between December 2018 and March 2019, Microsoft hosted a Machine Learning contest on Kaggle that challanged the participants\n",
    "to develop a prediction model able to preventively detect the presence of malware software in Windows machines efficiently.\n",
    "A prize in money of 25000$ was offered tot he winners, and the competition hosted more than 2400 teams.\n",
    "\n",
    "This problem was chosen as a team project for the \"EECS 221B - Advanced System Security\" graduate-level class of Fall 2019 in University of California Irvine. Being the contest already concluded, this solution will not be considered as an official participation, but as a research opportunity for further understanding common Machine Learning practices as long as exploring\n",
    "a real challange of the modern security industry.\n",
    "\n",
    "Jason Dellaluce (Team Leader), Ziwen Ning, Yibo Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import to_numeric\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the type of al the features, load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify all the features types\n",
    "features_useless = [\"MachineIdentifier\"]\n",
    "features_string = [\"ProductName\", \"EngineVersion\", \"AppVersion\", \"AvSigVersion\", \\\n",
    "                  \"RtpStateBitfield\", \"DefaultBrowsersIdentifier\", \\\n",
    "                   \"AVProductStatesIdentifier\", \"CountryIdentifier\", \"CityIdentifier\", \\\n",
    "                   \"OrganizationIdentifier\", \"GeoNameIdentifier\", \"LocaleEnglishNameIdentifier\", \\\n",
    "                   \"Platform\", \"Processor\", \"OsVer\", \"OsPlatformSubRelease\", \"OsBuildLab\", \\\n",
    "                   \"SkuEdition\", \"AutoSampleOptIn\", \"PuaMode\", \"SMode\", \"IeVerIdentifier\", \\\n",
    "                   \"SmartScreen\", \"Firewall\", \"UacLuaenable\", \"Census_MDC2FormFactor\", \\\n",
    "                   \"Census_DeviceFamily\", \"Census_OEMNameIdentifier\", \"Census_OEMModelIdentifier\", \\\n",
    "                   \"Census_ProcessorManufacturerIdentifier\", \"Census_ProcessorModelIdentifier\", \\\n",
    "                   \"Census_ProcessorClass\", \"Census_PrimaryDiskTypeName\", \\\n",
    "                   \"Census_ChassisTypeName\", \"Census_PowerPlatformRoleName\", \"Census_InternalBatteryType\", \\\n",
    "                   \"Census_OSVersion\", \"Census_OSArchitecture\", \"Census_OSBranch\", \"Census_OSEdition\", \\\n",
    "                   \"Census_OSSkuName\", \"Census_OSInstallTypeName\", \"Census_OSInstallLanguageIdentifier\", \\\n",
    "                   \"Census_OSUILocaleIdentifier\", \"Census_OSWUAutoUpdateOptionsName\", \\\n",
    "                   \"Census_GenuineStateName\", \"Census_ActivationChannel\", \\\n",
    "                   \"Census_FlightRing\", \\\n",
    "                   \"Census_ThresholdOptIn\", \"Census_FirmwareManufacturerIdentifier\", \"Census_FirmwareVersionIdentifier\", \\\n",
    "                   \"Wdft_RegionIdentifier\"]\n",
    "\n",
    "features_int = [\"AVProductsInstalled\", \"AVProductsEnabled\", \"OsBuild\", \"OsSuite\", \"Census_ProcessorCoreCount\", \\\n",
    "               \"Census_PrimaryDiskTotalCapacity\", \"Census_SystemVolumeTotalCapacity\", \"Census_TotalPhysicalRAM\", \\\n",
    "               \"Census_InternalPrimaryDisplayResolutionHorizontal\", \"Census_InternalPrimaryDisplayResolutionVertical\", \\\n",
    "                \"Census_InternalBatteryNumberOfCharges\", \"Census_OSBuildNumber\", \"Census_OSBuildRevision\"]\n",
    "\n",
    "features_float = [\"Census_InternalPrimaryDiagonalDisplaySizeInInches\"]\n",
    "\n",
    "features_bool = [\"IsBeta\", \"HasTpm\", \"IsSxsPassiveMode\", \"Census_HasOpticalDiskDrive\", \"IsProtected\", \\\n",
    "                 \"Census_IsPortableOperatingSystem\", \"Census_IsFlightingInternal\", \"Census_IsFlightsDisabled\", \\\n",
    "                 \"Census_IsSecureBootEnabled\", \"Census_IsWIMBootEnabled\", \"Census_IsVirtualDevice\", \\\n",
    "                 \"Census_IsTouchEnabled\", \"Census_IsPenCapable\", \"Census_IsAlwaysOnAlwaysConnectedCapable\", \\\n",
    "                 \"Wdft_IsGamer\", \"HasDetections\"]\n",
    "\n",
    "data_types = {}\n",
    "for x in features_string: data_types[x] = \"str\"\n",
    "for x in features_int: data_types[x] = \"Int64\"\n",
    "for x in features_float: data_types[x] = 'Float64'\n",
    "for x in features_bool: data_types[x] = \"Int64\"\n",
    "\n",
    "# Read Training and Testing Data Set from file\n",
    "dataset = read_csv(\"train.csv\", dtype=data_types)\n",
    "\n",
    "for x in features_string:\n",
    "    dataset[x] = dataset[x].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.copy()\n",
    "transformations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data statistics and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist(ax=pyplot.figure(figsize = (20,20)).gca())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial analysis of feature importance, looking for unbalanced or uncomplete ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats_features = []\n",
    "for col in train.columns:\n",
    "    stats_features.append((col, train[col].nunique(), train[col].isnull().sum() * 100 / train.shape[0], \\\n",
    "        train[col].value_counts(normalize=True, dropna=False).values[0] * 100, train [col].dtype))\n",
    "    \n",
    "pd.DataFrame(stats_features, columns=['Feature', 'Unique Values', '% of Missing Values', \\\n",
    "    '% of Biggest Category', 'type']).sort_values('% of Missing Values', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to remove all the features wit more than 50% of missing values, beacouse they can be meaningless in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stats_features:\n",
    "    if x[2] >= 50:\n",
    "        features_useless.append(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We isolate all the unbalanced features (when a category is more than 60% of all the values of the feature), which willr equire further investigation and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stats_features:\n",
    "    if x[0] not in features_useless and x[3] >= 60:\n",
    "        print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too much unbalanced features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided that if a feature has more than 90% of values in same category, then we can remove it from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stats_features:\n",
    "    if x[3] >= 90:\n",
    "        features_useless.append(x[0])\n",
    "        \n",
    "for x in stats_features:\n",
    "    if x[0] not in features_useless and x[3] >= 60:\n",
    "        print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features to investigate has been consstently reduced, we'll procede by analyzing every one of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVProductStatesIdentifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'AVProductStatesIdentifier'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceAvProductStatesIdentifier(df):\n",
    "    cur_feature = 'AVProductStatesIdentifier'\n",
    "    # Add new a category\n",
    "    df[cur_feature] = df[cur_feature].cat.add_categories([\"Other\"])\n",
    "\n",
    "    # Make the feature binary\n",
    "    df[cur_feature] = df[cur_feature].where(df[cur_feature] == \"53447\", \"Other\")\n",
    "\n",
    "    # Remove unused categories\n",
    "    df[cur_feature] = df[cur_feature].cat.remove_unused_categories()\n",
    "\n",
    "    # Write the results\n",
    "    df[cur_feature].value_counts(dropna=False, normalize=True) * 100\n",
    "    \n",
    "    return df\n",
    "\n",
    "transformations.append(balanceAvProductStatesIdentifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wdft_IsGamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Wdft_IsGamer'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceWdtf_IsGamer(df):\n",
    "    cur_feature = 'Wdft_IsGamer'\n",
    "    df[cur_feature] = df[cur_feature].where(df[cur_feature].notna(), 2)\n",
    "    return df\n",
    "\n",
    "transformations.append(balanceWdtf_IsGamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicate as 2 all the case in which its unknown if the user is a gamer, or if it's a casual gamer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census_IsTouchEnabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Census_IsTouchEnabled'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature cannot be improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census_GenuineStateName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Census_GenuineStateName'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceCensus_GenuineStateName(df):\n",
    "    cur_feature = 'Census_GenuineStateName'\n",
    "    df[cur_feature] = df[cur_feature].cat.add_categories([\"Other\"])\n",
    "    df[cur_feature] = df[cur_feature].where(df[cur_feature] == \"IS_GENUINE\", \"Other\")\n",
    "    df[cur_feature] = df[cur_feature].cat.remove_unused_categories()\n",
    "    df[cur_feature].value_counts(dropna=False, normalize=True) * 100\n",
    "    return df\n",
    "\n",
    "transformations.append(balanceCensus_GenuineStateName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census_PowerPlatformRoleName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Census_PowerPlatformRoleName'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceCensus_PowerPlatformRoleName(df):\n",
    "    cur_feature = 'Census_PowerPlatformRoleName'\n",
    "    df[cur_feature] = df[cur_feature].apply(lambda x: x if (x == 'Desktop' or x == 'Mobile') else 'Other')\n",
    "    df[cur_feature] = df[cur_feature].fillna('Other')\n",
    "    df[cur_feature] = df[cur_feature].astype('category')\n",
    "    df[cur_feature] = df[cur_feature].cat.remove_unused_categories()\n",
    "    df[cur_feature].value_counts(dropna=False, normalize=True) * 100\n",
    "    return df\n",
    "\n",
    "transformations.append(balanceCensus_PowerPlatformRoleName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census_PrimaryDiskTypeName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Census_PrimaryDiskTypeName'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceCensus_PrimaryDiskTypeName(df):\n",
    "    cur_feature = 'Census_PrimaryDiskTypeName'\n",
    "    df[cur_feature] = df[cur_feature].apply(lambda x: x if (x == 'HDD' or x == 'SSD') else 'Other')\n",
    "    df[cur_feature] = df[cur_feature].fillna('Other')\n",
    "    df[cur_feature] = df[cur_feature].astype('category')\n",
    "    df[cur_feature] = df[cur_feature].cat.remove_unused_categories()\n",
    "    df[cur_feature].value_counts(dropna=False, normalize=True) * 100\n",
    "    return df\n",
    "\n",
    "transformations.append(balanceCensus_PrimaryDiskTypeName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census_ProcessorManufacturerIdentifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Census_ProcessorManufacturerIdentifier'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceCensus_ProcessorManufacturerIdentifier(df):\n",
    "    cur_feature = 'Census_ProcessorManufacturerIdentifier'\n",
    "    df[cur_feature] = df[cur_feature].apply(lambda x: x if (x == '5') else 'Other')\n",
    "    df[cur_feature] = df[cur_feature].fillna('Other')\n",
    "    df[cur_feature] = df[cur_feature].astype('category')\n",
    "    df[cur_feature] = df[cur_feature].cat.remove_unused_categories()\n",
    "    df[cur_feature].value_counts(dropna=False, normalize=True) * 100\n",
    "    return df\n",
    "\n",
    "transformations.append(balanceCensus_ProcessorManufacturerIdentifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census_ProcessorCoreCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Census_ProcessorCoreCount'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceCensus_ProcessorCoreCount(df):\n",
    "    cur_feature = 'Census_ProcessorCoreCount'\n",
    "    df[cur_feature] = df[cur_feature].fillna(1)\n",
    "    return df\n",
    "\n",
    "transformations.append(balanceCensus_ProcessorCoreCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census_MDC2FormFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_feature = 'Census_MDC2FormFactor'\n",
    "train[cur_feature].value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceCensus_MDC2FormFactor(df):\n",
    "    cur_feature = 'Census_MDC2FormFactor'\n",
    "    df[cur_feature] = df[cur_feature].apply(lambda x: \"Server\" if (\"Server\" in x) else x)\n",
    "    df[cur_feature] = df[cur_feature].apply(lambda x: \"Desktop\" if (\"AllInOne\" in x or \"PCOther\" in x) else x)\n",
    "    df[cur_feature] = df[cur_feature].apply(lambda x: \"Portable\" if (\"Tablet\" in x or \"IoT\" in x or \"Detachable\" in x or \"Convertible\" in x) else x)\n",
    "    df[cur_feature] = df[cur_feature].fillna('Desktop')\n",
    "    df[cur_feature] = df[cur_feature].astype('category')\n",
    "    df[cur_feature] = df[cur_feature].cat.remove_unused_categories()\n",
    "    df[cur_feature].value_counts(dropna=False, normalize=True) * 100\n",
    "    return df\n",
    "\n",
    "transformations.append(balanceCensus_MDC2FormFactor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletion of useless features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEngineering(df):\n",
    "    df['EngineVersion_2'] = df['EngineVersion'].apply(lambda x: x.split('.')[2]).fillna(0).astype('category')\n",
    "    df['EngineVersion_3'] = df['EngineVersion'].apply(lambda x: x.split('.')[3]).fillna(0).astype('category')\n",
    "    features_string.append('EngineVersion_2')\n",
    "    features_string.append('EngineVersion_3')\n",
    "    features_useless.append('EngineVersion')\n",
    "    \n",
    "    df['AppVersion_1'] = df['AppVersion'].apply(lambda x: x.split('.')[1]).fillna(0).astype('category')\n",
    "    df['AppVersion_2'] = df['AppVersion'].apply(lambda x: x.split('.')[2]).fillna(0).astype('category')\n",
    "    df['AppVersion_3'] = df['AppVersion'].apply(lambda x: x.split('.')[3]).fillna(0).astype('category')\n",
    "    features_string.append('AppVersion_1')\n",
    "    features_string.append('AppVersion_2')\n",
    "    features_string.append('AppVersion_3')\n",
    "    features_useless.append('AppVersion')\n",
    "    \n",
    "    df['AvSigVersion_0'] = df['AvSigVersion'].apply(lambda x: x.split('.')[0]).fillna(0).astype('category')\n",
    "    df['AvSigVersion_1'] = df['AvSigVersion'].apply(lambda x: x.split('.')[1]).fillna(0).astype('category')\n",
    "    df['AvSigVersion_2'] = df['AvSigVersion'].apply(lambda x: x.split('.')[2]).fillna(0).astype('category')\n",
    "    features_string.append('AvSigVersion_0')\n",
    "    features_string.append('AvSigVersion_1')\n",
    "    features_string.append('AvSigVersion_2')\n",
    "    features_useless.append('AvSigVersion')\n",
    "    \n",
    "    df['Census_OSVersion_0'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[0]).fillna(0).astype('category')\n",
    "    df['Census_OSVersion_1'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[1]).fillna(0).astype('category')\n",
    "    df['Census_OSVersion_2'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[2]).fillna(0).astype('category')\n",
    "    df['Census_OSVersion_3'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[3]).fillna(0).astype('category')\n",
    "    features_string.append('Census_OSVersion_0')\n",
    "    features_string.append('Census_OSVersion_1')\n",
    "    features_string.append('Census_OSVersion_2')\n",
    "    features_string.append('Census_OSVersion_3')\n",
    "    features_useless.append('Census_OSVersion')\n",
    "    \n",
    "    # https://www.kaggle.com/adityaecdrid/simple-feature-engineering-xd\n",
    "    # Disk Capacity features\n",
    "    df['FE_SystemVolumeDiskRatio'] = df['Census_SystemVolumeTotalCapacity'] / df['Census_PrimaryDiskTotalCapacity']\n",
    "    df['FE_NonSystemVolumeDiskRatio'] = df['Census_PrimaryDiskTotalCapacity'] - df['Census_SystemVolumeTotalCapacity']\n",
    "\n",
    "    # Screen features\n",
    "    df['FE_DisplayAspectRatio'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'] / df['Census_InternalPrimaryDisplayResolutionVertical']\n",
    "    df['FE_DisplayDPI'] = ((df['Census_InternalPrimaryDisplayResolutionHorizontal']**2 + df['Census_InternalPrimaryDisplayResolutionVertical']**2)**.5) / (df['Census_InternalPrimaryDiagonalDisplaySizeInInches'])\n",
    "\n",
    "    # Processor features\n",
    "    df['FE_RamPerCore'] = df['Census_TotalPhysicalRAM'] / df['Census_ProcessorCoreCount']\n",
    "    \n",
    "    return df\n",
    "\n",
    "transformations.append(featureEngineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropUselessFeatures(df):\n",
    "    df = df.drop(columns=features_useless)\n",
    "    return df\n",
    "\n",
    "transformations.append(dropUselessFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeCategoricalFeatures(df):\n",
    "    # TODO: Specify categorical feature labeling (maybe LabelEncoder is just fine)\n",
    "    for feature in (features_string):\n",
    "        if feature not in features_useless:\n",
    "            # TODO: Handling NULL values\n",
    "            if \"NULL\" not in df[feature].cat.categories:\n",
    "                df[feature] = df[feature].cat.add_categories([\"NULL\"]) \n",
    "            train[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "            # Encode\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(df[feature])\n",
    "            df[feature] = encoder.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "transformations.append(encodeCategoricalFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing or null values for numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeNumericalNullValues(df):\n",
    "    # TODO: Specify special specific policies for null values\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "transformations.append(encodeNumericalNullValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in transformations:\n",
    "    print (t)\n",
    "    train = t(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randseed = 7\n",
    "Y = train[\"HasDetections\"].astype('int')\n",
    "X = train.drop([\"HasDetections\"], axis=1)\n",
    "\n",
    "# Fix RandomForest problem\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"Int64\":\n",
    "        X[col] = X[col].astype(np.int64)\n",
    "        \n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=randseed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to approach the problem as a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(randseed)\n",
    "tensorflow.random.set_seed(randseed)\n",
    "\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(70, input_dim=64, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(45, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "models = []\n",
    "models.append(( 'LR' , LogisticRegression(solver='lbfgs')))\n",
    "models.append(( 'NN' , KerasClassifier(build_fn=nn_model, epochs=100, batch_size=30, verbose=0)))\n",
    "models.append(( 'CART' , DecisionTreeClassifier()))\n",
    "models.append(( 'RANDFOREEST' , RandomForestClassifier(n_estimators=20)))\n",
    "models.append(( 'LIGHTGBM' , LGBMClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=randseed)\n",
    "    time_before = datetime.datetime.now()\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, error_score='raise', cv=kfold, scoring='accuracy')\n",
    "    time_after = datetime.datetime.now()\n",
    "    \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f), Duration: %d milliseconds\" % \\\n",
    "            (name, cv_results.mean(), \\\n",
    "            cv_results.std(),\n",
    "            int((time_after - time_before).total_seconds() * 1000))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While both RandomForest and LightGBM models showed good fitting performance on training data, LightGBM was evidently the most efficient one in terms of computational complexity. Such a model will be selected over the others to experiment parameter tuning and check the precision on training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/garethjns/microsoft-lightgbm-with-parameter-tuning-0-823\n",
    "# Common parameter setting, that showed good scores in other problems\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'reg_alpha': 1,\n",
    "          'reg_lambda': 1,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'random_state' : randseed,\n",
    "         }\n",
    "\n",
    "# Initialize parameter ranges for Grid Research\n",
    "gridParams = {\n",
    "    'learning_rate': [0.15, 0.1, 0.05, 0.001],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'num_leaves': [16, 31, 45, 64],\n",
    "    'boosting_type' : ['gbdt', 'dart', 'goss'],\n",
    "    'subsample' : [0.8, 1, 1.5],\n",
    "    'reg_alpha' : [0.75, 1, 1.25],\n",
    "    'reg_lambda' : [0.75, 1, 1.25],\n",
    "    'min_split_gain': [0.25, 0.5, 0.75],\n",
    "    }\n",
    "\n",
    "model = LGBMClassifier(\n",
    "            random_state = params['random_state'],\n",
    "            boosting_type = params['boosting_type'],\n",
    "            objective = params['objective'],\n",
    "            silent = True,\n",
    "            learning_rate = params['learning_rate'],\n",
    "            num_leaves = params['num_leaves'],\n",
    "            max_depth = params['max_depth'],\n",
    "            subsample_for_bin = params['subsample_for_bin'],\n",
    "            subsample = params['subsample'],\n",
    "            subsample_freq = params['subsample_freq'],\n",
    "            min_split_gain = params['min_split_gain'],\n",
    "            min_child_weight = params['min_child_weight'],\n",
    "            min_child_samples = params['min_child_samples'],\n",
    "            reg_alpha = params['reg_alpha'],\n",
    "            reg_lambda = params['reg_lambda'],\n",
    "            scale_pos_weight = params['scale_pos_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "grid = GridSearchCV(model, gridParams, verbose=1, cv=10)\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters obtained by the Grid Research will now be used to construct a final model, of which the precision will be measured on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "params['n_estimators'] = grid.best_params_['n_estimators']\n",
    "params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "params['boosting_type'] = grid.best_params_['boosting_type']\n",
    "params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "params['reg_lambda'] = grid.best_params_['reg_lambda']\n",
    "params['subsample'] = grid.best_params_['subsample']\n",
    "params['min_split_gain'] = grid.best_params_['min_split_gain']\n",
    "\n",
    "model = LGBMClassifier(\n",
    "            random_state = params['random_state'],\n",
    "            boosting_type = params['boosting_type'],\n",
    "            objective = params['objective'],\n",
    "            silent = True,\n",
    "            learning_rate = params['learning_rate'],\n",
    "            num_leaves = params['num_leaves'],\n",
    "            max_depth = params['max_depth'],\n",
    "            subsample_for_bin = params['subsample_for_bin'],\n",
    "            subsample = params['subsample'],\n",
    "            subsample_freq = params['subsample_freq'],\n",
    "            min_split_gain = params['min_split_gain'],\n",
    "            min_child_weight = params['min_child_weight'],\n",
    "            min_child_samples = params['min_child_samples'],\n",
    "            reg_alpha = params['reg_alpha'],\n",
    "            reg_lambda = params['reg_lambda'],\n",
    "            scale_pos_weight = params['scale_pos_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(sorted(zip(model.feature_importances_, X.columns)), columns=['Value','Feature'])\n",
    "pyplot.figure(figsize=(20, 15))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_importance.sort_values(by=\"Value\", ascending=False))\n",
    "pyplot.title('LightGBM Feature Importances')\n",
    "pyplot.tight_layout()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
